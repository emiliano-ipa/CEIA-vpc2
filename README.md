# CEIA ‚Äì Visi√≥n por Computadora II | Proyecto Final

Repositorio del proyecto final de la materia **Visi√≥n por Computadora II** de la Carrera de Especializaci√≥n en Inteligencia Artificial (CEIA ‚Äì UBA).

---

## üë• Integrantes

- **Mart√≠n Brocca** (<martinbrocca@gmail.com>)  
- **Emiliano Iparraguirre** (<emiliano.iparraguirre22@gmail.com>)  

---

## üéØ Objetivo general

El proyecto busca analizar y comparar distintos enfoques de **clasificaci√≥n de im√°genes** sobre un mismo dataset, pasando desde modelos cl√°sicos de *features ajustados manualmente* hasta arquitecturas modernas de **deep learning**.  

Los objetivos espec√≠ficos fueron:  
1. Explorar el dataset y evaluar la calidad y el balance de clases.  
2. Entrenar un baseline cl√°sico con descriptores de color y regresi√≥n log√≠stica.  
3. Desarrollar un baseline CNN con **ResNet18 congelada**.  
4. Mejorar el baseline aplicando **fine-tuning** y optimizaci√≥n de hiperpar√°metros con **Optuna**.  
5. Reestructurar el dataset en formato YOLO e implementar un modelo de clasificaci√≥n con **YOLOv8**.  
6. Comparar las m√©tricas finales de los diferentes enfoques.  

---

## üìÇ Notebooks principales

### 1. `01_EDA.ipynb` y `01.1_balance_check.ipynb`  
**Objetivo:** 

Realizar un an√°lisis exploratorio del dataset (EDA) y verificar el balance de clases.  

**Resultados esperados:**  
- Confirmar si el dataset estaba balanceado o no.
- Detectar clases con menor representaci√≥n para prever dificultades en el entrenamiento.
- Anticipar que m√©tricas como accuracy ser√≠an insuficientes y que ser√≠a necesario evaluar con **Macro-F1**.

**Conclusiones:**
- Se revis√≥ la distribuci√≥n de las categor√≠as.  
- Se identificaron posibles sesgos y la necesidad de aplicar estrategias de balance.  
- El dataset presenta cierta desproporci√≥n entre clases, lo que motiv√≥ la evaluaci√≥n con m√©tricas robustas al desbalance como **F1-score** adem√°s del accuracy.  

---

### 2. `02_Baseline_and_Optimized.ipynb`  
**Objetivo:** 

Comparar distintos enfoques de clasificaci√≥n para establecer una progresi√≥n desde un baseline simple hasta un modelo optimizado, y evaluar c√≥mo el uso de **transfer learning** y la **optimizaci√≥n de hiperpar√°metros** impactan en la performance del modelo.

**Estrategia:**  
- **Baseline cl√°sico:** extracci√≥n de histogramas de color y entrenamiento de una **regresi√≥n log√≠stica**.  
- **Baseline CNN:** uso de **ResNet18 pre-entrenada** con capas congeladas (solo se entrena el clasificador).  
- **Optimizaci√≥n:** liberaci√≥n de la capa `layer4` para fine-tuning y b√∫squeda de hiperpar√°metros con **Optuna**.  

**Resultados esperados:**  
- Que el modelo cl√°sico sirviera como punto de partida simple.  
- Que ResNet18 congelada mejorara significativamente el baseline cl√°sico.  
- Que el fine-tuning + Optuna aportara la mejor performance dentro del enfoque CNN, alcanzando el mejor **equilibrio entre accuracy y F1**, con mejoras notorias en clases dif√≠ciles como trash.  

**Conclusiones:**  
- El baseline cl√°sico logra resultados aceptables pero limitados.  
- ResNet18 congelada ya aporta una mejora clara.  
- El fine-tuning con Optuna optimiza a√∫n m√°s la capacidad de generalizaci√≥n del modelo.  

---

### 3. `03_YOLO.ipynb`  
**Objetivo:**  

Explorar un modelo distinto reestructurando el dataset en formato YOLO y evaluando **YOLOv8** para clasificaci√≥n.  

**Justificaci√≥n de la generaci√≥n de datasets aparte:**  
- YOLO requiere un formato espec√≠fico de organizaci√≥n de im√°genes y etiquetas.  
- Se dise√±√≥ un script para exportar los splits ya definidos (train, val, test) al formato requerido.  

**Estrategia:**  
- Comparar el desempe√±o de YOLO respecto a los CNN entrenados en PyTorch.

**Resultados esperados:**  
- Que YOLOv8, como arquitectura de deep learning originalmente dise√±ada para detecci√≥n, lograra resultados **competitivos o superiores** en clasificaci√≥n respecto a los CNN entrenados en PyTorch.
- Que alcanzara **alta accuracy Top-1** y que la **accuracy Top-5** fuera cercana a 1.0, reflejando su capacidad de incluir la clase correcta dentro de las mejores predicciones incluso cuando no era la primera opci√≥n.

**Conclusiones:**
- YOLOv8, incluso en su versi√≥n ligera (`yolov8n-cls`), alcanz√≥ un desempe√±o **muy superior** al de los modelos basados en CNN en t√©rminos de accuracy.  
- Logr√≥ un **Top-1 accuracy de 0.968** y un **Top-5 accuracy de 1.0**, lo que significa que en pr√°cticamente todos los casos acierta la clase correcta como primera opci√≥n y siempre la incluye dentro de las cinco predicciones m√°s probables.  
- Estos resultados confirman que YOLOv8 posee una **alta capacidad de generalizaci√≥n** y se posiciona como la arquitectura m√°s robusta dentro de los enfoques evaluados en este proyecto.  

---

## üìä Comparativo de resultados

### M√©tricas en el conjunto de **test**  

| Modelo / Estrategia                  | Accuracy | Macro-F1 | Comentarios clave |
|--------------------------------------|----------|----------|-------------------|
| ColorHist + Logistic Regression      | 0.567    | 0.556    | Baseline cl√°sico con histogramas de color. Buen desempe√±o en *cardboard*, pero pobre en clases m√°s dif√≠ciles (*glass*, *trash*). |
| ResNet18 (congelada, baseline CNN)   | 0.765    | 0.747    | Primer baseline con transfer learning congelado. Mejora sustancial frente al baseline cl√°sico, con buenos resultados en *glass* y *metal*, aunque *trash* sigue siendo dif√≠cil. |
| ResNet18 (fine-tuning + Optuna)      | 0.868    | 0.855    | Fine-tuning de `layer4` con hiperpar√°metros optimizados v√≠a Optuna. Logra el mejor Macro-F1 en test, con balance equitativo entre clases y mejoras notorias en *trash*. |
| **YOLOv8 (clasificaci√≥n)**               | **0.968 (Top-1)** / **1.0 (Top-5)** | ‚Äì | **En ~97% de los casos el modelo predice correctamente la clase en primer lugar. En el 100% de los casos, la clase verdadera aparece dentro de las 5 predicciones.** |

---

## üìù Conclusiones finales

- El **baseline cl√°sico** con histogramas de color y regresi√≥n log√≠stica resulta insuficiente para clases dif√≠ciles, aunque ofrece un punto de partida para el an√°lisis.  
- La **ResNet18 congelada** mejora claramente los resultados, validando el aporte del *transfer learning* incluso con un entrenamiento m√≠nimo.  
- El **fine-tuning de capas profundas con Optuna** obtiene el mejor **Macro-F1 (0.855)**, mostrando un balance m√°s justo entre clases y un salto de calidad en la predicci√≥n de *trash*.  
- **YOLOv8**, una arquitectura de deep learning originalmente dise√±ada para detecci√≥n de objetos y utilizada aqu√≠ en su variante de clasificaci√≥n, supera a los anteriores en accuracy (Top-1: 0.968, Top-5: 1.0). El resultado implica que en casi todos los casos acierta la clase correcta como primera opci√≥n y siempre la incluye dentro de las cinco mejores predicciones.  
- En conjunto, se concluye que las estrategias de **transfer learning + optimizaci√≥n** y el uso de **arquitecturas avanzadas** como YOLO permiten alcanzar resultados de alta precisi√≥n y robustez en este problema de clasificaci√≥n.  